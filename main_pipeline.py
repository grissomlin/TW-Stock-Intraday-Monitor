# -*- coding: utf-8 -*-
import os, sys, requests, time, json
from datetime import datetime, timedelta
from dotenv import load_dotenv
import pandas as pd
import yfinance as yf
from io import StringIO
import warnings
from tqdm import tqdm

# å¿½ç•¥è­¦å‘Šè¨Šæ¯
warnings.filterwarnings('ignore')

# ========== æ‰‹å‹•æ·»åŠ è·¯å¾‘ ==========
# åœ¨ GitHub Actions ä¸­ï¼Œéœ€è¦æ˜ç¢ºæ·»åŠ ç•¶å‰ç›®éŒ„åˆ° Python è·¯å¾‘
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

# å˜—è©¦å°å…¥è‡ªè¨‚æ¨¡çµ„
AI_AVAILABLE = False
ai_analyzer = None
StockPrompts = None

try:
    from ai_analyzer import StockAIAnalyzer
    from prompts import StockPrompts
    AI_AVAILABLE = True
    print("âœ… AIæ¨¡çµ„å°å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âš ï¸ AIæ¨¡çµ„å°å…¥å¤±æ•—: {e}")
    print("å˜—è©¦é‡æ–°å°å…¥...")
    
    # å˜—è©¦å¦ä¸€ç¨®å°å…¥æ–¹å¼
    try:
        # ç›´æ¥å¾ç•¶å‰ç›®éŒ„å°å…¥
        import importlib.util
        
        # å°å…¥ ai_analyzer
        ai_analyzer_path = os.path.join(current_dir, "ai_analyzer.py")
        spec = importlib.util.spec_from_file_location("ai_analyzer", ai_analyzer_path)
        ai_analyzer_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(ai_analyzer_module)
        StockAIAnalyzer = ai_analyzer_module.StockAIAnalyzer
        
        # å°å…¥ prompts
        prompts_path = os.path.join(current_dir, "prompts.py")
        spec = importlib.util.spec_from_file_location("prompts", prompts_path)
        prompts_module = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(prompts_module)
        StockPrompts = prompts_module.StockPrompts
        
        AI_AVAILABLE = True
        print("âœ… AIæ¨¡çµ„å‹•æ…‹å°å…¥æˆåŠŸ")
    except Exception as e2:
        print(f"âŒ AIæ¨¡çµ„å‹•æ…‹å°å…¥å¤±æ•—: {e2}")
        AI_AVAILABLE = False

# ========== è¼‰å…¥ç’°å¢ƒè®Šæ•¸ ==========
load_dotenv()

# ç’°å¢ƒè®Šæ•¸æª¢æŸ¥
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
TG_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
TG_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

print(f"ğŸ”§ ç’°å¢ƒè®Šæ•¸æª¢æŸ¥:")
print(f"  SUPABASE_URL: {'å·²è¨­ç½®' if SUPABASE_URL else 'æœªè¨­ç½®'}")
print(f"  SUPABASE_KEY: {'å·²è¨­ç½®' if SUPABASE_KEY else 'æœªè¨­ç½®'}")
print(f"  TG_TOKEN: {'å·²è¨­ç½®' if TG_TOKEN else 'æœªè¨­ç½®'}")
print(f"  TG_CHAT_ID: {'å·²è¨­ç½®' if TG_CHAT_ID else 'æœªè¨­ç½®'}")
print(f"  GEMINI_API_KEY: {'å·²è¨­ç½®' if GEMINI_API_KEY else 'æœªè¨­ç½®'}")
print(f"  AIæ¨¡çµ„å¯ç”¨: {AI_AVAILABLE}")

# ========== åˆå§‹åŒ– ==========
from supabase import create_client

# åˆå§‹åŒ– Supabase
supabase = None
if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ Supabase åˆå§‹åŒ–å¤±æ•—: {e}")
else:
    print("âš ï¸ Supabase ç’°å¢ƒè®Šæ•¸æœªè¨­ç½®")

# åˆå§‹åŒ– AI åˆ†æå™¨
if AI_AVAILABLE and GEMINI_API_KEY and supabase:
    try:
        ai_analyzer = StockAIAnalyzer(GEMINI_API_KEY, supabase)
        print("âœ… AIåˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ AIåˆ†æå™¨åˆå§‹åŒ–å¤±æ•—: {e}")
        ai_analyzer = None
else:
    print("âš ï¸ AIåˆ†æå™¨æœªåˆå§‹åŒ– (æª¢æŸ¥: AI_AVAILABLE={AI_AVAILABLE}, GEMINI_API_KEY={'å·²è¨­ç½®' if GEMINI_API_KEY else 'æœªè¨­ç½®'}, supabase={'å·²é€£æ¥' if supabase else 'æœªé€£æ¥'})")

# ========== æ—¥èªŒè¨­å®š ==========
def log(msg: str, level="INFO"):
    """è‡ªå®šç¾©æ—¥èªŒå‡½æ•¸"""
    timestamp = datetime.now().strftime('%H:%M:%S')
    formatted_msg = f"{timestamp}: {msg}"
    print(formatted_msg, flush=True)

# ========== åŠŸèƒ½æ¨¡çµ„ ==========
def send_telegram_msg(message):
    """ç™¼é€è¨Šæ¯åˆ° Telegram"""
    if not TG_TOKEN or not TG_CHAT_ID:
        log("âš ï¸ Telegram æ†‘è­‰æœªè¨­ç½®")
        return
    
    url = f"https://api.telegram.org/bot{TG_TOKEN}/sendMessage"
    payload = {
        "chat_id": TG_CHAT_ID,
        "text": message,
        "parse_mode": "Markdown",
        "disable_web_page_preview": True
    }
    
    try:
        response = requests.post(url, json=payload, timeout=10)
        if response.status_code == 200:
            log(f"Telegram è¨Šæ¯ç™¼é€æˆåŠŸ")
        else:
            log(f"Telegram ç™¼é€å¤±æ•—: {response.status_code}")
    except Exception as e:
        log(f"Telegram ç™¼é€éŒ¯èª¤: {e}")


def get_taiwan_stock_list():
    """ç²å–å°ç£å®Œæ•´è‚¡ç¥¨æ¸…å–®"""
    url_configs = [
        {'name': 'listed', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=1&issuetype=1&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'dr', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=J&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=2&issuetype=4&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'etf', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=1&issuetype=I&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'rotc', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=E&issuetype=R&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'tw_innovation', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=C&issuetype=C&industry_code=&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'otc_innovation', 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=A&issuetype=C&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
    ]
    
    all_stocks = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    log("é–‹å§‹ç²å–å°ç£è‚¡ç¥¨æ¸…å–®...")
    
    for config in url_configs:
        log(f"ç²å– {config['name']} é¡åˆ¥...")
        
        try:
            time.sleep(0.5)
            response = requests.get(config['url'], headers=headers, timeout=15)
            response.raise_for_status()
            response.encoding = 'big5'
            
            df = pd.read_html(StringIO(response.text), header=0)[0]
            count = 0
            
            for _, row in df.iterrows():
                code = str(row['æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ']).strip()
                name = str(row['æœ‰åƒ¹è­‰åˆ¸åç¨±']).strip()
                
                if 4 <= len(code) <= 6 and 'æ¬Šè­‰' not in name:
                    stock_data = {
                        'symbol': f"{code}{config['suffix']}",
                        'name': name,
                        'sector': row['ç”¢æ¥­åˆ¥'] if 'ç”¢æ¥­åˆ¥' in row else 'å…¶ä»–',
                        'is_rotc': (config['name'] == 'rotc')
                    }
                    all_stocks.append(stock_data)
                    count += 1
            
            log(f"âœ… å·²ç²å– {config['name']} {count} æª”è‚¡ç¥¨")
            
        except Exception as e:
            log(f"âŒ ç²å– {config['name']} å¤±æ•—: {str(e)[:30]}")
            continue
    
    if all_stocks:
        df_stocks = pd.DataFrame(all_stocks).drop_duplicates(subset=['symbol'])
        log(f"ğŸ“Š ç¸½å…±ç²å– {len(df_stocks)} æª”è‚¡ç¥¨")
        return df_stocks.to_dict('records')
    else:
        log("âŒ ç„¡æ³•ç²å–ä»»ä½•è‚¡ç¥¨è³‡æ–™")
        return []

def get_stock_price_data(symbol, max_retries=2):
    """ç²å–è‚¡ç¥¨åƒ¹æ ¼æ•¸æ“šï¼ˆæ”¹é€²ç‰ˆï¼‰"""
    for attempt in range(max_retries):
        try:
            df = yf.download(symbol, period="2d", progress=False, timeout=10)
            
            if df.empty or len(df) < 2:
                if attempt < max_retries - 1:
                    time.sleep(1)
                    continue
                return None, None, None
            
            if 'Close' in df.columns:
                close_data = df['Close']
                if len(close_data) >= 2:
                    curr_close = close_data.iloc[-1]
                    prev_close = close_data.iloc[-2]
                    
                    if pd.isna(curr_close) or pd.isna(prev_close) or prev_close == 0:
                        return None, None, None
                    
                    ret = (float(curr_close) / float(prev_close)) - 1
                    return ret, float(curr_close), float(prev_close)
            
            return None, None, None
            
        except Exception as e:
            if attempt < max_retries - 1:
                time.sleep(1)
                continue
            return None, None, None
    
    return None, None, None

def get_consecutive_limit_up_days(symbol):
    """æŸ¥è©¢é€£çºŒæ¼²åœå¤©æ•¸ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    try:
        if not supabase:
            return 1
        
        today = datetime.now().strftime("%Y-%m-%d")
        five_days_ago = (datetime.now() - timedelta(days=5)).strftime("%Y-%m-%d")
        
        response = supabase.table("individual_stock_analysis")\
            .select("analysis_date, return_rate, is_rotc")\
            .eq("symbol", symbol)\
            .gte("analysis_date", five_days_ago)\
            .lte("analysis_date", today)\
            .order("analysis_date", desc=False)\
            .execute()
        
        if not response.data:
            return 1
        
        consecutive_days = 0
        
        # æŒ‰æ—¥æœŸæ’åºï¼ˆå¾èˆŠåˆ°æ–°ï¼‰
        sorted_records = sorted(response.data, key=lambda x: x['analysis_date'])
        
        # å¾æ˜¨å¤©é–‹å§‹æª¢æŸ¥é€£çºŒæ¼²åœ
        for record in sorted_records[-5:]:  # åªçœ‹æœ€è¿‘5å¤©
            return_rate = record.get('return_rate')
            is_rotc = record.get('is_rotc', False)
            threshold = 0.10 if is_rotc else 0.098
            
            # æª¢æŸ¥ return_rate æ˜¯å¦ç‚º None
            if return_rate is None:
                break
                
            if float(return_rate) >= threshold:
                consecutive_days += 1
            else:
                break
        
        return max(consecutive_days, 1)
        
    except Exception as e:
        log(f"æŸ¥è©¢é€£çºŒæ¼²åœå¤©æ•¸å¤±æ•— {symbol}: {e}")
        return 11

def save_stock_with_analysis(stock_info):
    """å„²å­˜è‚¡ç¥¨åˆ†æè³‡è¨Šåˆ°è³‡æ–™åº«"""
    if not supabase:
        return False
    
    try:
        today_str = datetime.now().strftime("%Y-%m-%d")
        
        data = {
            "analysis_date": today_str,
            "symbol": stock_info['symbol'],
            "stock_name": stock_info['name'],
            "sector": stock_info.get('sector', ''),
            "return_rate": stock_info.get('return', 0),
            "price": stock_info.get('price', 0),
            "is_rotc": stock_info.get('is_rotc', False),
            "ai_comment": stock_info.get('ai_comment', ''),
            "consecutive_days": stock_info.get('consecutive_days', 1),
            "volume_ratio": stock_info.get('volume_ratio'),
            "created_at": datetime.now().isoformat()
        }
        
        # ä½¿ç”¨ upsert
        supabase.table("individual_stock_analysis").upsert(
            data,
            on_conflict='analysis_date,symbol'
        ).execute()
        
        return True
        
    except Exception as e:
        log(f"å„²å­˜è‚¡ç¥¨åˆ†æå¤±æ•— {stock_info['symbol']}: {e}")
        return False

def save_sector_analysis(sector_name, stocks_in_sector, ai_analysis):
    """å„²å­˜ç”¢æ¥­åˆ†æ"""
    if not supabase:
        return False
    
    try:
        today_str = datetime.now().strftime("%Y-%m-%d")
        
        data = {
            "analysis_date": today_str,
            "sector_name": sector_name,
            "stock_count": len(stocks_in_sector),
            "stocks_included": json.dumps([s['symbol'] for s in stocks_in_sector]),
            "ai_analysis": ai_analysis,
            "created_at": datetime.now().isoformat()
        }
        
        supabase.table("sector_analysis").upsert(data).execute()
        return True
        
    except Exception as e:
        log(f"å„²å­˜ç”¢æ¥­åˆ†æå¤±æ•— {sector_name}: {e}")
        return False

def update_consecutive_limit_up(stock_info):
    """æ›´æ–°é€£çºŒæ¼²åœè¿½è¹¤è¡¨"""
    if not supabase:
        return
    
    try:
        symbol = stock_info['symbol']
        consecutive_days = stock_info.get('consecutive_days', 1)
        today_str = datetime.now().strftime("%Y-%m-%d")
        
        if consecutive_days == 1:
            # ç¬¬ä¸€æ ¹æ¼²åœï¼Œå»ºç«‹æ–°ç´€éŒ„
            data = {
                "symbol": symbol,
                "start_date": today_str,
                "consecutive_days": 1,
                "status": "ongoing",
                "updated_at": datetime.now().isoformat()
            }
            supabase.table("consecutive_limit_up").upsert(data, on_conflict='symbol').execute()
        else:
            # æ›´æ–°é€£çºŒå¤©æ•¸
            supabase.table("consecutive_limit_up")\
                .update({
                    "consecutive_days": consecutive_days,
                    "status": "ongoing",
                    "updated_at": datetime.now().isoformat()
                })\
                .eq("symbol", symbol)\
                .execute()
                
    except Exception as e:
        log(f"æ›´æ–°é€£çºŒæ¼²åœè¿½è¹¤å¤±æ•— {stock_info['symbol']}: {e}")

def send_layered_notifications(stocks, sector_analyses, market_summary):
    """åˆ†å±¤æ¨æ’­é€šçŸ¥"""
    
    # 1. å€‹è‚¡æ¨æ’­ï¼ˆæœ€å¤š10æª”ï¼‰
    log("ğŸ“¤ ç™¼é€å€‹è‚¡æ¨æ’­é€šçŸ¥...")
    top_stocks = sorted(stocks, key=lambda x: x.get('consecutive_days', 1), reverse=True)[:10]
    
    for stock in top_stocks:
        days = stock.get('consecutive_days', 1)
        
        if days >= 3:
            emoji = "ğŸš€ğŸš€ğŸš€"
            priority = "ğŸ”¥ğŸ”¥ğŸ”¥"
        elif days == 2:
            emoji = "ğŸš€ğŸš€"
            priority = "ğŸ”¥ğŸ”¥"
        else:
            emoji = "ğŸš€"
            priority = "ğŸ”¥"
        
        ai_preview = stock.get('ai_comment', '')[:100] if stock.get('ai_comment') else ''
        
        msg = (
            f"{emoji} *{priority} å¼·å‹¢è‚¡: {stock['name']}* ({stock['symbol']})\n"
            f"ğŸ“ˆ æ¼²å¹…: {stock['return']:.2%} | é€£æ¿: {days}å¤©\n"
            f"ğŸ’µ åƒ¹æ ¼: {stock['price']:.2f}\n"
            f"ğŸ·ï¸ é¡åˆ¥: {'èˆˆæ«ƒ' if stock['is_rotc'] else 'ä¸Šå¸‚/ä¸Šæ«ƒ'}\n"
            f"ğŸ“Š ç”¢æ¥­: {stock['sector']}"
        )
        
        if ai_preview:
            msg += f"\nğŸ¤– AI: {ai_preview}..."
        
        send_telegram_msg(msg)
        time.sleep(0.1)
    
    # 2. ç”¢æ¥­æ¨æ’­ï¼ˆæœ€å¤š5å€‹ç”¢æ¥­ï¼‰
    if sector_analyses:
        log("ğŸ“¤ ç™¼é€ç”¢æ¥­è¶¨å‹¢æ¨æ’­...")
        for sector, analysis in list(sector_analyses.items())[:5]:
            stocks_count = len([s for s in stocks if s.get('sector') == sector])
            
            # æ‰¾å‡ºç”¢æ¥­é¾é ­
            sector_stocks = [s for s in stocks if s.get('sector') == sector]
            if sector_stocks:
                leader = max(sector_stocks, key=lambda x: x.get('consecutive_days', 1))
                leader_days = leader.get('consecutive_days', 1)
                
                msg = (
                    f"ğŸ­ *ç”¢æ¥­è¶¨å‹¢: {sector}*\n"
                    f"ğŸ“Š æ¼²åœå®¶æ•¸: {stocks_count}å®¶\n"
                    f"ğŸ‘‘ é¾é ­è‚¡: {leader['name']}({leader_days}é€£æ¿)\n"
                    f"ğŸ¤– AIåˆ†æ: {analysis[:200]}..."
                )
            else:
                msg = (
                    f"ğŸ­ *ç”¢æ¥­è¶¨å‹¢: {sector}*\n"
                    f"ğŸ“Š æ¼²åœå®¶æ•¸: {stocks_count}å®¶\n"
                    f"ğŸ¤– AIåˆ†æ: {analysis[:200]}..."
                )
            
            send_telegram_msg(msg)
            time.sleep(0.1)
    
    # 3. å¸‚å ´ç¸½çµæ¨æ’­
    if market_summary:
        log("ğŸ“¤ ç™¼é€å¸‚å ´ç¸½çµæ¨æ’­...")
        
        total_stocks = len(stocks)
        rotc_count = sum(1 for s in stocks if s.get('is_rotc'))
        main_count = total_stocks - rotc_count
        avg_consecutive = sum(s.get('consecutive_days', 1) for s in stocks) / total_stocks if total_stocks > 0 else 0
        
        msg = (
            f"ğŸ“Š *ä»Šæ—¥å¸‚å ´AIç¸½çµ*\n"
            f"ğŸ“ˆ ç¸½æ¼²åœ: {total_stocks}æª”\n"
            f"ğŸ“Š ä¸Šå¸‚æ«ƒ: {main_count} | èˆˆæ«ƒ: {rotc_count}\n"
            f"ğŸ“… å¹³å‡é€£æ¿: {avg_consecutive:.1f}å¤©\n"
            f"ğŸ¤– å¸‚å ´åˆ†æ: {market_summary[:300]}..."
        )
        
        send_telegram_msg(msg)

# ========== 4. ä¸»åŸ·è¡Œé‚è¼¯ ==========
def run_monitor():
    start_time = time.time()
    log("ğŸš€ å•Ÿå‹•å°è‚¡æ¼²åœæ¿æƒæç³»çµ±ï¼ˆAIå¢å¼·ç‰ˆï¼‰...")
    log(f"é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æª¢æŸ¥é€£ç·š
    if not supabase:
        log("âš ï¸ Supabase é€£ç·šå¤±æ•—ï¼Œå°‡åªé€²è¡Œæƒæä¸å„²å­˜è³‡æ–™")
    
    # ç²å–è‚¡ç¥¨æ¸…å–®
    stocks = get_taiwan_stock_list()
    
    if not stocks:
        log("âŒ ç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®ï¼Œç¨‹åºçµ‚æ­¢")
        send_telegram_msg("âŒ *è‚¡ç¥¨ç›£æ§å¤±æ•—*\nç„¡æ³•ç²å–è‚¡ç¥¨æ¸…å–®")
        return
    
    # ç™¼é€é–‹å§‹é€šçŸ¥
    send_telegram_msg(
        f"ğŸ”” *å°è‚¡æ¼²åœæ¿æƒæå•Ÿå‹•*\n"
        f"æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        f"æ¨™çš„ç¸½æ•¸: {len(stocks)}"
    )
    
    total_stocks = len(stocks)
    log(f"é–‹å§‹æƒæ {total_stocks} æª”è‚¡ç¥¨...")
    
    found_count = 0
    limit_up_stocks = []
    error_count = 0
    
    # æº–å‚™ symbol åˆ—è¡¨
    symbols = [stock['symbol'] for stock in stocks]
    stock_dict = {stock['symbol']: stock for stock in stocks}
    
    # æ‰¹é‡ä¸‹è¼‰
    batch_size = 150
    batches = [symbols[i:i + batch_size] for i in range(0, len(symbols), batch_size)]
    
    # æƒææ¼²åœè‚¡ç¥¨
    for batch_idx, batch_symbols in enumerate(tqdm(batches, desc="æ‰¹æ¬¡é€²åº¦", unit="batch")):
        try:
            df_batch = yf.download(batch_symbols, period="2d", progress=False, group_by='ticker')
            
            for symbol in batch_symbols:
                try:
                    stock_info = stock_dict[symbol]
                    if symbol not in df_batch:
                        error_count += 1
                        continue
                    
                    df = df_batch[symbol]
                    close_data = df['Close'].dropna()
                    if len(close_data) < 2:
                        error_count += 1
                        continue
                    
                    curr_close = close_data.iloc[-1]
                    prev_close = close_data.iloc[-2]
                    
                    if pd.isna(curr_close) or pd.isna(prev_close) or prev_close == 0:
                        error_count += 1
                        continue
                    
                    ret = (curr_close / prev_close) - 1
                    threshold = 0.1 if stock_info['is_rotc'] else 0.098
                    
                    if ret >= threshold:
                        info = {
                            'symbol': symbol,
                            'name': stock_info['name'],
                            'sector': stock_info['sector'],
                            'return': ret,
                            'price': float(curr_close),
                            'prev_close': float(prev_close),
                            'is_rotc': stock_info['is_rotc'],
                            'consecutive_days': 1  # ç¨å¾Œæœƒè¨ˆç®—
                        }
                        limit_up_stocks.append(info)
                        found_count += 1
                        
                except Exception as e:
                    error_count += 1
                    continue
                    
        except Exception as e:
            log(f"æ‰¹æ¬¡ {batch_idx} ä¸‹è¼‰å¤±æ•—: {e}")
            error_count += len(batch_symbols)
        
        time.sleep(1)
    
    log(f"æƒæå®Œæˆï¼Œç™¼ç¾ {found_count} æª”æ¼²åœè‚¡ç¥¨")
    
    # ========== AIåˆ†æéšæ®µ ==========
    if limit_up_stocks and ai_analyzer:
        log("ğŸ¤– é–‹å§‹AIåˆ†æéšæ®µ...")
        
        # 1. è¨ˆç®—é€£çºŒæ¼²åœå¤©æ•¸
        log("ğŸ“… è¨ˆç®—é€£çºŒæ¼²åœå¤©æ•¸...")
        for stock in limit_up_stocks:
            stock['consecutive_days'] = get_consecutive_limit_up_days(stock['symbol'])
        
        # 2. å€‹è‚¡AIåˆ†æ
        log("ğŸ§  é€²è¡Œå€‹è‚¡AIåˆ†æ...")
        for stock in tqdm(limit_up_stocks, desc="å€‹è‚¡AIåˆ†æ"):
            try:
                ai_comment = ai_analyzer.analyze_individual_stock(stock)
                if ai_comment:
                    stock['ai_comment'] = ai_comment
                    save_stock_with_analysis(stock)
                    update_consecutive_limit_up(stock)
                time.sleep(0.5)  # é¿å…APIé™åˆ¶
            except Exception as e:
                log(f"å€‹è‚¡AIåˆ†æå¤±æ•— {stock['symbol']}: {e}")
        
        # 3. ç”¢æ¥­AIåˆ†æ
        log("ğŸ­ é€²è¡Œç”¢æ¥­AIåˆ†æ...")
        sector_groups = {}
        for stock in limit_up_stocks:
            sector = stock.get('sector', 'å…¶ä»–')
            if sector not in sector_groups:
                sector_groups[sector] = []
            sector_groups[sector].append(stock)
        
        sector_analyses = {}
        for sector, stocks_in_sector in sector_groups.items():
            if len(stocks_in_sector) > 1:  # åŒç”¢æ¥­è¶…é1å®¶æ‰åˆ†æ
                try:
                    analysis = ai_analyzer.analyze_sector(sector, stocks_in_sector)
                    if analysis:
                        sector_analyses[sector] = analysis
                        save_sector_analysis(sector, stocks_in_sector, analysis)
                    time.sleep(0.5)
                except Exception as e:
                    log(f"ç”¢æ¥­AIåˆ†æå¤±æ•— {sector}: {e}")
        
        # 4. å¸‚å ´AIåˆ†æ
        log("ğŸ“Š é€²è¡Œå¸‚å ´AIåˆ†æ...")
        market_summary = None
        try:
            market_summary = ai_analyzer.analyze_market_summary(limit_up_stocks)
        except Exception as e:
            log(f"å¸‚å ´AIåˆ†æå¤±æ•—: {e}")
        
        # 5. ç™¼é€åˆ†å±¤é€šçŸ¥
        send_layered_notifications(limit_up_stocks, sector_analyses, market_summary)
        
        # 6. æ›´æ–°å¸‚å ´ç¸½çµ
        if market_summary and supabase:
            try:
                today_str = datetime.now().strftime("%Y-%m-%d")
                safe_data = {
                    "analysis_date": today_str,
                    "stock_count": total_stocks,
                    "summary_content": market_summary[:5000],  # é™åˆ¶é•·åº¦
                    "stock_list": ", ".join([s['name'] + '(' + s['symbol'] + ')' for s in limit_up_stocks]) if limit_up_stocks else "ç„¡",
                    "created_at": datetime.now().isoformat()
                }
                supabase.table("daily_market_summary").upsert(safe_data).execute()
            except Exception as e:
                log(f"æ›´æ–°å¸‚å ´ç¸½çµå¤±æ•—: {e}")
    
    # è¨ˆç®—åŸ·è¡Œæ™‚é–“
    elapsed_time = time.time() - start_time
    minutes = int(elapsed_time // 60)
    seconds = int(elapsed_time % 60)
    
    # ç™¼é€çµæŸé€šçŸ¥
    msg_end = (
        f"ğŸ *æƒæä»»å‹™çµæŸ*\n"
        f"â±ï¸ åŸ·è¡Œæ™‚é–“: {minutes}åˆ†{seconds}ç§’\n"
        f"âœ… ç¸½æƒæ: {total_stocks} æª”\n"
        f"âœ… ç™¼ç¾æ¼²åœ: {found_count} æª”\n"
        f"âš ï¸ éŒ¯èª¤æ•¸é‡: {error_count} å€‹"
    )
    
    if limit_up_stocks:
        msg_end += f"\n\nğŸ“Š ä»Šæ—¥æ¼²åœæ¿ ({len(limit_up_stocks)}æª”):"
        sorted_stocks = sorted(limit_up_stocks, key=lambda x: x.get('consecutive_days', 1), reverse=True)
        for i, stock in enumerate(sorted_stocks[:10], 1):
            days = stock.get('consecutive_days', 1)
            stock_type = "èˆˆ" if stock['is_rotc'] else "æ™®"
            msg_end += f"\n{i}. {stock['name']}({stock['symbol']}): {stock['return']:.2%} [{days}é€£æ¿]"
    
    send_telegram_msg(msg_end)
    
    # ç”Ÿæˆçµ±è¨ˆå ±å‘Š
    log("\n" + "="*60)
    log("ğŸ“Š æƒæçµ±è¨ˆå ±å‘Š")
    log(f"ç¸½è‚¡ç¥¨æ•¸: {total_stocks}")
    log(f"æˆåŠŸæƒæ: {total_stocks - error_count}")
    log(f"éŒ¯èª¤æ•¸é‡: {error_count}")
    log(f"æ¼²åœæ¿æ•¸: {found_count}")
    log(f"åŸ·è¡Œæ™‚é–“: {minutes}åˆ†{seconds}ç§’")
    
    if limit_up_stocks:
        rotc_count = sum(1 for stock in limit_up_stocks if stock['is_rotc'])
        main_count = found_count - rotc_count
        log(f"ä¸Šå¸‚/ä¸Šæ«ƒæ¼²åœ: {main_count} æª”")
        log(f"èˆˆæ«ƒæ¼²åœ: {rotc_count} æª”")
        
        # ç”¢æ¥­åˆ†ä½ˆ
        sector_counts = {}
        for stock in limit_up_stocks:
            sector = stock['sector']
            sector_counts[sector] = sector_counts.get(sector, 0) + 1
        
        log("ğŸ­ ç”¢æ¥­åˆ†ä½ˆ:")
        for sector, count in sorted(sector_counts.items(), key=lambda x: x[1], reverse=True)[:10]:
            log(f" {sector}: {count}æª”")
    
    log("="*60)

if __name__ == "__main__":
    try:
        run_monitor()
    except KeyboardInterrupt:
        log("\nâš ï¸ ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·")
        send_telegram_msg("â¹ï¸ *ç¨‹å¼è¢«ä½¿ç”¨è€…ä¸­æ–·*")
    except Exception as e:
        log(f"âŒ ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤: {e}")
        send_telegram_msg(f"âŒ *ç¨‹å¼åŸ·è¡ŒéŒ¯èª¤*\néŒ¯èª¤è¨Šæ¯: {str(e)[:100]}")



