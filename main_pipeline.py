# -*- coding: utf-8 -*-
import os, io, requests, time, random
from datetime import datetime
from dotenv import load_dotenv
import pandas as pd
import yfinance as yf
from io import StringIO
from supabase import create_client
import google.generativeai as genai 
from tqdm import tqdm

# å¼·åˆ¶è¼‰å…¥ç•¶å‰ç›®éŒ„ä¸‹çš„ .env
load_dotenv(dotenv_path=os.path.join(os.getcwd(), '.env'))

# ========== 1. åˆå§‹åŒ–è¨­å®š ==========
# å¾ç’°å¢ƒè®Šæ•¸è®€å– (GitHub Secrets / Streamlit Secrets / .env)
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# å»ºç«‹ Supabase é€£ç·š
if SUPABASE_URL and SUPABASE_KEY:
    supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
else:
    print("âŒ è­¦å‘Š: æ‰¾ä¸åˆ° Supabase URL æˆ– Keyï¼Œè³‡æ–™åº«åŠŸèƒ½å°‡å¤±æ•ˆã€‚")

def get_ai_model_client():
    """åˆå§‹åŒ– AI å®¢æˆ¶ç«¯ä¸¦å›å‚³æ¨¡å‹å¯¦ä¾‹"""
    if not GEMINI_API_KEY:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ å¤±æ•—: æ‰¾ä¸åˆ° GEMINI_API_KEYã€‚")
        return None, None
    
    # é®ç½©é¡¯ç¤º Key ç”¨æ–¼èª¿è©¦ (åªé¡¯ç¤ºå‰ 4 ç¢¼èˆ‡å¾Œ 4 ç¢¼)
    masked_key = f"{GEMINI_API_KEY[:4]}****{GEMINI_API_KEY[-4:]}"
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ğŸ”‘ å·²è®€å– API Key: {masked_key}")

    try:
        genai.configure(api_key=GEMINI_API_KEY)
        
        # ç²å–å¯ç”¨æ¨¡å‹æ¸…å–®
        all_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
        
        # å„ªå…ˆé¸æ“‡ flash æ¨¡å‹ (é€Ÿåº¦å¿«ã€å…è²»é¡åº¦é«˜)
        candidates = ['models/gemini-1.5-flash', 'models/gemini-1.5-pro', 'gemini-1.5-flash', 'gemini-1.5-pro']
        target_model_name = next((c for c in candidates if c in all_models), all_models[0] if all_models else None)
        
        if target_model_name:
            model = genai.GenerativeModel(target_model_name)
            print(f"[{datetime.now().strftime('%H:%M:%S')}] âœ… AI å•Ÿå‹•æˆåŠŸ! ä½¿ç”¨æ¨¡å‹: {target_model_name}")
            return model, target_model_name
        
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âš ï¸ æ‰¾ä¸åˆ°æ”¯æ´çš„æ¨¡å‹ã€‚")
        return None, None
    except Exception as e:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] âŒ AI åˆå§‹åŒ–ç•°å¸¸: {str(e)}")
        return None, None

# åŸ·è¡Œåˆå§‹åŒ–
ai_client, active_model_name = get_ai_model_client()

def log(msg: str):
    tqdm.write(f"{datetime.now().strftime('%H:%M:%S')}: {msg}")

# ========== 2. ç²å–å…¨å¸‚å ´è‚¡ç¥¨æ¸…å–® ==========
def get_comprehensive_stock_list():
    url_configs = [
        {'name': 'ä¸Šå¸‚', 'is_rotc': False, 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=1&issuetype=1&Page=1&chklike=Y', 'suffix': '.TW'},
        {'name': 'ä¸Šæ«ƒ', 'is_rotc': False, 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?market=2&issuetype=4&Page=1&chklike=Y', 'suffix': '.TWO'},
        {'name': 'èˆˆæ«ƒ', 'is_rotc': True, 'url': 'https://isin.twse.com.tw/isin/class_main.jsp?owncode=&stockname=&isincode=&market=E&issuetype=R&industry_code=&Page=1&chklike=Y', 'suffix': '.TWO'},
    ]
    all_stocks = []
    headers = {'User-Agent': 'Mozilla/5.0'}
    for cfg in url_configs:
        try:
            resp = requests.get(cfg['url'], timeout=20, headers=headers)
            resp.encoding = 'big5'
            dfs = pd.read_html(StringIO(resp.text), header=0)
            if not dfs: continue
            df = dfs[0]
            for _, row in df.iterrows():
                code = str(row.get('æœ‰åƒ¹è­‰åˆ¸ä»£è™Ÿ', '')).strip()
                name = str(row.get('æœ‰åƒ¹è­‰åˆ¸åç¨±', '')).strip()
                sector = str(row.get('ç”¢æ¥­åˆ¥', 'å…¶ä»–')).strip()
                if 4 <= len(code) <= 6 and not any(x in name for x in ["è³¼", "å”®", "ç‰›", "ç†Š"]):
                    all_stocks.append({
                        'symbol': f"{code}{cfg['suffix']}", 
                        'name': name, 
                        'sector': sector, 
                        'is_rotc': cfg['is_rotc']
                    })
        except Exception as e:
            log(f"âš ï¸ è®€å– {cfg['name']} å¤±æ•—: {e}")
            continue
    return pd.DataFrame(all_stocks).drop_duplicates(subset=['symbol'])

# ========== 3. AI åˆ†æé‚è¼¯ ==========
def ai_single_stock_analysis(stock_name, symbol, sector):
    if not ai_client: 
        return "AI Client æœªå•Ÿå‹•"
    
    today_str = datetime.now().strftime("%Y-%m-%d")

    try:
        # 1. æª¢æŸ¥å¿«å–
        existing = supabase.table("individual_stock_analysis") \
            .select("ai_comment") \
            .eq("analysis_date", today_str) \
            .eq("symbol", symbol) \
            .execute()

        if existing.data and len(existing.data) > 0:
            cached_comment = existing.data[0]['ai_comment']
            if "é¡åº¦å·²é”ä¸Šé™" not in cached_comment:
                return cached_comment

        # 2. å‘¼å« Gemini
        prompt = f"ä½ æ˜¯å°è‚¡å°ˆå®¶ã€‚è«‹ç”¨30å­—å…§ç°¡è¿°ã€Œ{stock_name}({symbol})ã€ä»Šæ—¥å¤§æ¼²å¯èƒ½åŸå› ã€‚ç”¢æ¥­ï¼š{sector}ã€‚"
        response = ai_client.generate_content(prompt)
        ai_msg = response.text.strip()
        
        # 3. å„²å­˜çµæœ
        supabase.table("individual_stock_analysis").upsert({
            "analysis_date": today_str,
            "symbol": symbol,
            "stock_name": stock_name,
            "sector": sector,
            "ai_comment": ai_msg
        }, on_conflict="analysis_date,symbol").execute()
        
        return ai_msg

    except Exception as e:
        if "429" in str(e):
            return "API é™æµä¸­"
        return f"åˆ†æå¤±æ•—: {str(e)[:20]}"

# ========== 4. è‚¡åƒ¹åµæ¸¬ ==========
def process_single_stock(stock):
    symbol = stock['symbol']
    try:
        df = yf.download(symbol, period="2d", progress=False, threads=False, timeout=10)
        if df.empty or len(df) < 2: return None
        
        # è™•ç† yfinance å¯èƒ½çš„å¤šå±¤ç´¢å¼•
        if isinstance(df.columns, pd.MultiIndex):
            df.columns = df.columns.get_level_values(0)
            
        last_close = float(df['Close'].iloc[-2])
        curr_close = float(df['Close'].iloc[-1])
        curr_high = float(df['High'].iloc[-1])
        ret_vs_prev = (curr_close / last_close) - 1

        # åˆ¤å®šè¦å‰‡ï¼šèˆˆæ«ƒç„¡æ¼²è·Œå¹…é™åˆ¶(è¨­ç‚º10%)ï¼Œä¸Šå¸‚æ«ƒä»¥9.8%ç‚ºé–€æª»
        is_strong = (stock['is_rotc'] and ret_vs_prev >= 0.1) or \
                    (not stock['is_rotc'] and ret_vs_prev >= 0.098)

        if is_strong:
            ai_comment = ai_single_stock_analysis(stock['name'], symbol, stock['sector'])
            return {**stock, 'pct': f"{ret_vs_prev:.2%}", 'ai_comment': ai_comment}
            
    except: return None
    return None

# ========== 5. ä¸»ç¨‹å¼ ==========
def run_monitor():
    start_ts = time.time()
    
    # å†æ¬¡ç¢ºèª AI ç‹€æ…‹
    if not ai_client:
        log("âŒ æ³¨æ„ï¼šAI æ¨¡çµ„æœªå•Ÿå‹•ï¼Œå°‡åƒ…é€²è¡Œæ•¸æ“šæƒæã€‚")
    
    stocks_df = get_comprehensive_stock_list()
    stocks_list = stocks_df.to_dict('records')
    
    limit_ups = []
    log(f"ğŸš€ é–‹å§‹å…¨å¸‚å ´æƒæ ({len(stocks_list)} æª”)...")

    # ä½¿ç”¨ tqdm é¡¯ç¤ºé€²åº¦æ¢
    for s in tqdm(stocks_list, desc="æƒæé€²åº¦"):
        res = process_single_stock(s)
        if res:
            limit_ups.append(res)
            log(f"ğŸ”¥ å¼·å‹¢è‚¡: {res['name']} | æ¼²å¹…: {res['pct']} | AI: {res['ai_comment']}")
        
        # ç¨å¾®å»¶é²é¿å…è¢« Yahoo å°é– IP
        time.sleep(0.05)

    log(f"ğŸ ä»»å‹™çµæŸã€‚å…±ç™¼ç¾ {len(limit_ups)} æª”å¼·å‹¢è‚¡ã€‚è€—æ™‚: {(time.time() - start_ts)/60:.1f} åˆ†é˜")

if __name__ == "__main__":
    run_monitor()
